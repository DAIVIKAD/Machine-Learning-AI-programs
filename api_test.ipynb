{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0EB5T6P/s4yMXgbh4TkXP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAIVIKAD/Machine-Learning-AI-programs/blob/main/api_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HIhSAhZCR-hC",
        "outputId": "35b26121-c989-4af9-ddd8-8ef7c305df4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GROQ_API_KEY found in environment. Please paste it (input is hidden):\n",
            "GROQ_API_KEY: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1030612624.py:69: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  start_ts = datetime.utcnow().isoformat() + \"Z\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started at 2025-11-12T13:36:40.469121Z\n",
            "Fetching available models from Groq...\n",
            "Found 20 models. Showing up to MAX_TESTS=25.\n",
            "[1/20] Testing model: moonshotai/kimi-k2-instruct ... OK\n",
            "[2/20] Testing model: qwen/qwen3-32b ... OK\n",
            "[3/20] Testing model: openai/gpt-oss-20b ... OK\n",
            "[4/20] Testing model: openai/gpt-oss-safeguard-20b ... OK\n",
            "[5/20] Testing model: playai-tts-arabic ... FAILED\n",
            "[6/20] Testing model: moonshotai/kimi-k2-instruct-0905 ... OK\n",
            "[7/20] Testing model: whisper-large-v3 ... FAILED\n",
            "[8/20] Testing model: openai/gpt-oss-120b ... OK\n",
            "[9/20] Testing model: whisper-large-v3-turbo ... FAILED\n",
            "[10/20] Testing model: groq/compound ... OK\n",
            "[11/20] Testing model: groq/compound-mini ... OK\n",
            "[12/20] Testing model: allam-2-7b ... OK\n",
            "[13/20] Testing model: meta-llama/llama-guard-4-12b ... OK\n",
            "[14/20] Testing model: playai-tts ... FAILED\n",
            "[15/20] Testing model: meta-llama/llama-prompt-guard-2-86m ... FAILED\n",
            "[16/20] Testing model: llama-3.3-70b-versatile ... OK\n",
            "[17/20] Testing model: meta-llama/llama-prompt-guard-2-22m ... FAILED\n",
            "[18/20] Testing model: llama-3.1-8b-instant ... OK\n",
            "[19/20] Testing model: meta-llama/llama-4-maverick-17b-128e-instruct ... OK\n",
            "[20/20] Testing model: meta-llama/llama-4-scout-17b-16e-instruct ... OK\n",
            "Results written to: /content/groq_model_test_results.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                         model_id     ok  status_code  \\\n",
              "0                     moonshotai/kimi-k2-instruct   True          200   \n",
              "1                                  qwen/qwen3-32b   True          200   \n",
              "2                              openai/gpt-oss-20b   True          200   \n",
              "3                    openai/gpt-oss-safeguard-20b   True          200   \n",
              "4                               playai-tts-arabic  False          400   \n",
              "5                moonshotai/kimi-k2-instruct-0905   True          200   \n",
              "6                                whisper-large-v3  False          400   \n",
              "7                             openai/gpt-oss-120b   True          200   \n",
              "8                          whisper-large-v3-turbo  False          400   \n",
              "9                                   groq/compound   True          200   \n",
              "10                             groq/compound-mini   True          200   \n",
              "11                                     allam-2-7b   True          200   \n",
              "12                   meta-llama/llama-guard-4-12b   True          200   \n",
              "13                                     playai-tts  False          400   \n",
              "14            meta-llama/llama-prompt-guard-2-86m  False          400   \n",
              "15                        llama-3.3-70b-versatile   True          200   \n",
              "16            meta-llama/llama-prompt-guard-2-22m  False          400   \n",
              "17                           llama-3.1-8b-instant   True          200   \n",
              "18  meta-llama/llama-4-maverick-17b-128e-instruct   True          200   \n",
              "19      meta-llama/llama-4-scout-17b-16e-instruct   True          200   \n",
              "\n",
              "                                       short_response  \\\n",
              "0                                 MODEL_OK tiny-model   \n",
              "1   <think>\\nOkay, the user wants me to test conne...   \n",
              "2   {'id': 'chatcmpl-0890c431-8096-460a-af1f-c580b...   \n",
              "3   {'id': 'chatcmpl-defc941a-3ca9-4168-bad4-e887d...   \n",
              "4                                                None   \n",
              "5                        MODEL_OK tiny_test_assistant   \n",
              "6                                                None   \n",
              "7   {'id': 'chatcmpl-cfa93e4f-53ed-445e-805a-c1582...   \n",
              "8                                                None   \n",
              "9                                   MODEL_OK Compound   \n",
              "10                             MODEL_OK compound-mini   \n",
              "11                                       MODEL_OK001    \n",
              "12                                               safe   \n",
              "13                                               None   \n",
              "14                                               None   \n",
              "15                                     MODEL_OK LLaMA   \n",
              "16                                               None   \n",
              "17                                      MODEL_OK 1234   \n",
              "18                                MODEL_OK tiny_model   \n",
              "19                                     MODEL_OK 12345   \n",
              "\n",
              "                                                error  \n",
              "0                                                None  \n",
              "1                                                None  \n",
              "2                                                None  \n",
              "3                                                None  \n",
              "4   {\"error\":{\"message\":\"The model `playai-tts-ara...  \n",
              "5                                                None  \n",
              "6   {\"error\":{\"message\":\"The model `whisper-large-...  \n",
              "7                                                None  \n",
              "8   {\"error\":{\"message\":\"The model `whisper-large-...  \n",
              "9                                                None  \n",
              "10                                               None  \n",
              "11                                               None  \n",
              "12                                               None  \n",
              "13  {\"error\":{\"message\":\"The model `playai-tts` re...  \n",
              "14  {\"error\":{\"message\":\"failed to template reques...  \n",
              "15                                               None  \n",
              "16  {\"error\":{\"message\":\"failed to template reques...  \n",
              "17                                               None  \n",
              "18                                               None  \n",
              "19                                               None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66bb13d8-6ab9-4e39-8b9f-6e9406102a39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_id</th>\n",
              "      <th>ok</th>\n",
              "      <th>status_code</th>\n",
              "      <th>short_response</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moonshotai/kimi-k2-instruct</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK tiny-model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qwen/qwen3-32b</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>&lt;think&gt;\\nOkay, the user wants me to test conne...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>openai/gpt-oss-20b</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>{'id': 'chatcmpl-0890c431-8096-460a-af1f-c580b...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>openai/gpt-oss-safeguard-20b</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>{'id': 'chatcmpl-defc941a-3ca9-4168-bad4-e887d...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>playai-tts-arabic</td>\n",
              "      <td>False</td>\n",
              "      <td>400</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"error\":{\"message\":\"The model `playai-tts-ara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>moonshotai/kimi-k2-instruct-0905</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK tiny_test_assistant</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>whisper-large-v3</td>\n",
              "      <td>False</td>\n",
              "      <td>400</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"error\":{\"message\":\"The model `whisper-large-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>openai/gpt-oss-120b</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>{'id': 'chatcmpl-cfa93e4f-53ed-445e-805a-c1582...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>whisper-large-v3-turbo</td>\n",
              "      <td>False</td>\n",
              "      <td>400</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"error\":{\"message\":\"The model `whisper-large-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>groq/compound</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK Compound</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>groq/compound-mini</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK compound-mini</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>allam-2-7b</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK001</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>meta-llama/llama-guard-4-12b</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>safe</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>playai-tts</td>\n",
              "      <td>False</td>\n",
              "      <td>400</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"error\":{\"message\":\"The model `playai-tts` re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>meta-llama/llama-prompt-guard-2-86m</td>\n",
              "      <td>False</td>\n",
              "      <td>400</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"error\":{\"message\":\"failed to template reques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>llama-3.3-70b-versatile</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK LLaMA</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>meta-llama/llama-prompt-guard-2-22m</td>\n",
              "      <td>False</td>\n",
              "      <td>400</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"error\":{\"message\":\"failed to template reques...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>llama-3.1-8b-instant</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK 1234</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>meta-llama/llama-4-maverick-17b-128e-instruct</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK tiny_model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>meta-llama/llama-4-scout-17b-16e-instruct</td>\n",
              "      <td>True</td>\n",
              "      <td>200</td>\n",
              "      <td>MODEL_OK 12345</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66bb13d8-6ab9-4e39-8b9f-6e9406102a39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66bb13d8-6ab9-4e39-8b9f-6e9406102a39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66bb13d8-6ab9-4e39-8b9f-6e9406102a39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-34476581-165e-4d3b-b09b-6c4f8312542a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34476581-165e-4d3b-b09b-6c4f8312542a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-34476581-165e-4d3b-b09b-6c4f8312542a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    main()\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"moonshotai/kimi-k2-instruct\",\n          \"llama-3.1-8b-instant\",\n          \"llama-3.3-70b-versatile\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ok\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 94,\n        \"min\": 200,\n        \"max\": 400,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          400,\n          200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"short_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"safe\",\n          \"MODEL_OK 1234\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"{\\\"error\\\":{\\\"message\\\":\\\"The model `whisper-large-v3` does not support chat completions\\\",\\\"type\\\":\\\"invalid_request_error\\\"}}\\n\",\n          \"{\\\"error\\\":{\\\"message\\\":\\\"failed to template request: failed to render text output: messages must contains a single user message for text classification models\\\",\\\"type\\\":\\\"invalid_request_error\\\"}}\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Inspect the CSV or DataFrame above. If you want to test all models, increase MAX_TESTS.\n"
          ]
        }
      ],
      "source": [
        "# Colab-ready script to list Groq models and test chat completions\n",
        "# Save this cell and run. Requires 'requests' (preinstalled in Colab).\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import csv\n",
        "import time\n",
        "from getpass import getpass\n",
        "from datetime import datetime\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "# Config\n",
        "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")  # prefer env var\n",
        "if not GROQ_API_KEY:\n",
        "    print(\"No GROQ_API_KEY found in environment. Please paste it (input is hidden):\")\n",
        "    GROQ_API_KEY = getpass(\"GROQ_API_KEY: \").strip()\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "MODELS_ENDPOINT = \"https://api.groq.com/openai/v1/models\"\n",
        "CHAT_ENDPOINT = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "# Safety / run limits\n",
        "MAX_TESTS = 25  # change if you want to test more models (cost & rate-limit considerations)\n",
        "REQUEST_TIMEOUT = 30  # seconds\n",
        "PAUSE_BETWEEN = 0.25  # seconds between requests to be polite\n",
        "\n",
        "def get_models():\n",
        "    r = requests.get(MODELS_ENDPOINT, headers=HEADERS, timeout=REQUEST_TIMEOUT)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    # Many APIs return { \"data\": [ { \"id\": \"model-name\", ...}, ... ] }\n",
        "    if isinstance(data, dict) and \"data\" in data and isinstance(data[\"data\"], list):\n",
        "        return [m.get(\"id\") or m.get(\"model\") or m for m in data[\"data\"]]\n",
        "    # fallback: maybe models returned as list\n",
        "    if isinstance(data, list):\n",
        "        return [m.get(\"id\") if isinstance(m, dict) else m for m in data]\n",
        "    # otherwise return raw\n",
        "    return data\n",
        "\n",
        "def test_model_chat(model_id):\n",
        "    # Small, safe test prompt. Keeps response short by instructing a tiny structured reply.\n",
        "    payload = {\n",
        "        \"model\": model_id,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a tiny test assistant that must reply with a single short line.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Test connectivity. Reply exactly 'MODEL_OK' followed by the model id.\"}\n",
        "        ],\n",
        "        \"max_tokens\": 32,\n",
        "        \"temperature\": 0.0\n",
        "    }\n",
        "    try:\n",
        "        r = requests.post(CHAT_ENDPOINT, headers=HEADERS, json=payload, timeout=REQUEST_TIMEOUT)\n",
        "        # capture status and body\n",
        "        return {\n",
        "            \"ok\": r.ok,\n",
        "            \"status_code\": r.status_code,\n",
        "            \"response_json\": r.json() if r.content else None,\n",
        "            \"error_text\": None if r.ok else r.text[:1000]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"ok\": False, \"status_code\": None, \"response_json\": None, \"error_text\": str(e)}\n",
        "\n",
        "def main():\n",
        "    start_ts = datetime.utcnow().isoformat() + \"Z\"\n",
        "    print(f\"Started at {start_ts}\")\n",
        "    print(\"Fetching available models from Groq...\")\n",
        "    try:\n",
        "        raw_models = get_models()\n",
        "    except Exception as e:\n",
        "        print(\"Failed to fetch models:\", e)\n",
        "        return\n",
        "\n",
        "    # normalize model ids (if list of dicts etc)\n",
        "    if not isinstance(raw_models, list):\n",
        "        print(\"Unexpected models response (not a list). Here's the raw content:\")\n",
        "        print(raw_models)\n",
        "        return\n",
        "\n",
        "    model_ids = []\n",
        "    for m in raw_models:\n",
        "        if isinstance(m, str):\n",
        "            model_ids.append(m)\n",
        "        elif isinstance(m, dict):\n",
        "            # common key names\n",
        "            for k in (\"id\", \"model\", \"name\"):\n",
        "                if k in m:\n",
        "                    model_ids.append(m[k])\n",
        "                    break\n",
        "            else:\n",
        "                # fallback serialize\n",
        "                model_ids.append(str(m))\n",
        "\n",
        "    print(f\"Found {len(model_ids)} models. Showing up to MAX_TESTS={MAX_TESTS}.\")\n",
        "    to_test = model_ids[:MAX_TESTS]\n",
        "\n",
        "    results = []\n",
        "    for idx, mid in enumerate(to_test, start=1):\n",
        "        print(f\"[{idx}/{len(to_test)}] Testing model: {mid}\", end=\" ... \", flush=True)\n",
        "        res = test_model_chat(mid)\n",
        "        if res[\"ok\"] and res[\"response_json\"]:\n",
        "            # try to pull generated text safely\n",
        "            text = None\n",
        "            try:\n",
        "                # Groq chat response shape is 'choices' or 'output' depending on API version\n",
        "                js = res[\"response_json\"]\n",
        "                # try common OpenAI-compatible shape\n",
        "                choices = js.get(\"choices\")\n",
        "                if choices and isinstance(choices, list) and len(choices) > 0:\n",
        "                    # prefer message content\n",
        "                    c0 = choices[0]\n",
        "                    if \"message\" in c0 and isinstance(c0[\"message\"], dict):\n",
        "                        text = c0[\"message\"].get(\"content\")\n",
        "                    else:\n",
        "                        text = c0.get(\"text\") or c0.get(\"message\")\n",
        "                # fallback: 'text' or 'output' in top-level\n",
        "                if not text:\n",
        "                    text = js.get(\"text\") or str(js.get(\"output\") or js)\n",
        "            except Exception:\n",
        "                text = str(res[\"response_json\"])\n",
        "            print(\"OK\")\n",
        "        else:\n",
        "            text = None\n",
        "            print(\"FAILED\")\n",
        "        results.append({\n",
        "            \"model_id\": mid,\n",
        "            \"ok\": bool(res[\"ok\"]),\n",
        "            \"status_code\": res[\"status_code\"],\n",
        "            \"short_response\": (text[:400] if isinstance(text, str) else None),\n",
        "            \"error\": res[\"error_text\"]\n",
        "        })\n",
        "        time.sleep(PAUSE_BETWEEN)\n",
        "\n",
        "    # Save results to CSV\n",
        "    csv_path = \"/content/groq_model_test_results.csv\"\n",
        "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"model_id\",\"ok\",\"status_code\",\"short_response\",\"error\"])\n",
        "        writer.writeheader()\n",
        "        for r in results:\n",
        "            writer.writerow(r)\n",
        "    print(\"Results written to:\", csv_path)\n",
        "\n",
        "    # show dataframe for quick inspection in Colab\n",
        "    df = pd.DataFrame(results)\n",
        "    display(df)\n",
        "    print(\"Done. Inspect the CSV or DataFrame above. If you want to test all models, increase MAX_TESTS.\")\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}